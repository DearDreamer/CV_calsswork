{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#为方便上传和查看代码，将在pycharm上运行的py文件直接复制到jupyter上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db4cf5",
   "metadata": {},
   "source": [
    "### data_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfe862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "\n",
    "def train_hr_transform(crop_size):\n",
    "    return Compose([\n",
    "        RandomCrop(crop_size),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def train_lr_transform(crop_size, upscale_factor):\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "def display_transform():\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(400),\n",
    "        CenterCrop(400),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "class TrainDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
    "        super(TrainDatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.hr_transform = train_hr_transform(crop_size)\n",
    "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
    "        lr_image = self.lr_transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class ValDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super(ValDatasetFromFolder, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index])\n",
    "        w, h = hr_image.size\n",
    "        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
    "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
    "        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
    "        hr_image = CenterCrop(crop_size)(hr_image)\n",
    "        lr_image = lr_scale(hr_image)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class TestDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super(TestDatasetFromFolder, self).__init__()\n",
    "        self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
    "        self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
    "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.lr_filenames[index].split('/')[-1]\n",
    "        lr_image = Image.open(self.lr_filenames[index])\n",
    "        w, h = lr_image.size\n",
    "        hr_image = Image.open(self.hr_filenames[index])\n",
    "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_filenames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccc4ed",
   "metadata": {},
   "source": [
    "### loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30392177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.vgg import vgg16\n",
    "\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = vgg16(pretrained=True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss()\n",
    "\n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        # Adversarial Loss\n",
    "        adversarial_loss = torch.mean(1 - out_labels)\n",
    "        # Perception Loss\n",
    "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        # Image Loss\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        # TV Loss\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    g_loss = GeneratorLoss()\n",
    "    print(g_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255940a",
   "metadata": {},
   "source": [
    "### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31752efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from math import log10\n",
    "\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_ssim\n",
    "from data_utils import TrainDatasetFromFolder, ValDatasetFromFolder, display_transform\n",
    "from loss import GeneratorLoss\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train Super Resolution Models')\n",
    "parser.add_argument('--crop_size', default=88, type=int, help='training images crop size')\n",
    "parser.add_argument('--upscale_factor', default=4, type=int, choices=[2, 4, 8],\n",
    "                    help='super resolution upscale factor')\n",
    "parser.add_argument('--num_epochs', default=100, type=int, help='train epoch number')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    opt = parser.parse_args()\n",
    "    \n",
    "    CROP_SIZE = opt.crop_size\n",
    "    UPSCALE_FACTOR = opt.upscale_factor\n",
    "    NUM_EPOCHS = opt.num_epochs\n",
    "    \n",
    "    train_set = TrainDatasetFromFolder('data/DIV2K_train_HR', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
    "    val_set = ValDatasetFromFolder('data/DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)\n",
    "    train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)\n",
    "    \n",
    "    netG = Generator(UPSCALE_FACTOR)\n",
    "    print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
    "    netD = Discriminator()\n",
    "    print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
    "    \n",
    "    generator_criterion = GeneratorLoss()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        netG.cuda()\n",
    "        netD.cuda()\n",
    "        generator_criterion.cuda()\n",
    "    \n",
    "    optimizerG = optim.Adam(netG.parameters())\n",
    "    optimizerD = optim.Adam(netD.parameters())\n",
    "    \n",
    "    results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        train_bar = tqdm(train_loader)\n",
    "        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
    "    \n",
    "        netG.train()\n",
    "        netD.train()\n",
    "        for data, target in train_bar:\n",
    "            g_update_first = True\n",
    "            batch_size = data.size(0)\n",
    "            running_results['batch_sizes'] += batch_size\n",
    "    \n",
    "            ############################\n",
    "            # (1) Update D network: maximize D(x)-1-D(G(z))\n",
    "            ###########################\n",
    "            real_img = Variable(target)\n",
    "            if torch.cuda.is_available():\n",
    "                real_img = real_img.cuda()\n",
    "            z = Variable(data)\n",
    "            if torch.cuda.is_available():\n",
    "                z = z.cuda()\n",
    "            fake_img = netG(z)\n",
    "    \n",
    "            netD.zero_grad()\n",
    "            real_out = netD(real_img).mean()\n",
    "            fake_out = netD(fake_img).mean()\n",
    "            d_loss = 1 - real_out + fake_out\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            optimizerD.step()\n",
    "    \n",
    "            ############################\n",
    "            # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            ## The two lines below are added to prevent runetime error in Google Colab ##\n",
    "            fake_img = netG(z)\n",
    "            fake_out = netD(fake_img).mean()\n",
    "            ##\n",
    "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
    "            g_loss.backward()\n",
    "            \n",
    "            fake_img = netG(z)\n",
    "            fake_out = netD(fake_img).mean()\n",
    "            \n",
    "            \n",
    "            optimizerG.step()\n",
    "\n",
    "            # loss for current batch before optimization \n",
    "            running_results['g_loss'] += g_loss.item() * batch_size\n",
    "            running_results['d_loss'] += d_loss.item() * batch_size\n",
    "            running_results['d_score'] += real_out.item() * batch_size\n",
    "            running_results['g_score'] += fake_out.item() * batch_size\n",
    "    \n",
    "            train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
    "                epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "                running_results['g_loss'] / running_results['batch_sizes'],\n",
    "                running_results['d_score'] / running_results['batch_sizes'],\n",
    "                running_results['g_score'] / running_results['batch_sizes']))\n",
    "    \n",
    "        netG.eval()\n",
    "        out_path = 'training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader)\n",
    "            valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
    "            val_images = []\n",
    "            for val_lr, val_hr_restore, val_hr in val_bar:\n",
    "                batch_size = val_lr.size(0)\n",
    "                valing_results['batch_sizes'] += batch_size\n",
    "                lr = val_lr\n",
    "                hr = val_hr\n",
    "                if torch.cuda.is_available():\n",
    "                    lr = lr.cuda()\n",
    "                    hr = hr.cuda()\n",
    "                sr = netG(lr)\n",
    "        \n",
    "                batch_mse = ((sr - hr) ** 2).data.mean()\n",
    "                valing_results['mse'] += batch_mse * batch_size\n",
    "                batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
    "                valing_results['ssims'] += batch_ssim * batch_size\n",
    "                valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\n",
    "                valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
    "                val_bar.set_description(\n",
    "                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
    "                        valing_results['psnr'], valing_results['ssim']))\n",
    "        \n",
    "                val_images.extend(\n",
    "                    [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
    "                     display_transform()(sr.data.cpu().squeeze(0))])\n",
    "            val_images = torch.stack(val_images)\n",
    "            val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
    "            val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
    "            index = 1\n",
    "            for image in val_save_bar:\n",
    "                image = utils.make_grid(image, nrow=3, padding=5)\n",
    "                utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
    "                index += 1\n",
    "    \n",
    "        # save model parameters\n",
    "        torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
    "        torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
    "        # save loss\\scores\\psnr\\ssim\n",
    "        results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
    "        results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
    "        results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
    "        results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
    "        results['psnr'].append(valing_results['psnr'])\n",
    "        results['ssim'].append(valing_results['ssim'])\n",
    "    \n",
    "        if epoch % 10 == 0 and epoch != 0:\n",
    "            out_path = 'statistics/'\n",
    "            data_frame = pd.DataFrame(\n",
    "                data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
    "                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
    "                index=range(1, epoch + 1))\n",
    "            data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc16b17",
   "metadata": {},
   "source": [
    "### test_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "from model import Generator\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Test Single Image')\n",
    "parser.add_argument('--upscale_factor', default=4, type=int, help='super resolution upscale factor')\n",
    "parser.add_argument('--test_mode', default='GPU', type=str, choices=['GPU', 'CPU'], help='using GPU or CPU')\n",
    "parser.add_argument('--image_name', type=str, help='test low resolution image name')\n",
    "parser.add_argument('--model_name', default='netG_epoch_4_100.pth', type=str, help='generator model epoch name')\n",
    "opt = parser.parse_args()\n",
    "\n",
    "UPSCALE_FACTOR = opt.upscale_factor\n",
    "TEST_MODE = True if opt.test_mode == 'GPU' else False\n",
    "IMAGE_NAME = opt.image_name\n",
    "MODEL_NAME = opt.model_name\n",
    "\n",
    "model = Generator(UPSCALE_FACTOR).eval()\n",
    "if TEST_MODE:\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load('epochs/' + MODEL_NAME))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('epochs/' + MODEL_NAME, map_location=lambda storage, loc: storage))\n",
    "\n",
    "image = Image.open(IMAGE_NAME)\n",
    "image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\n",
    "if TEST_MODE:\n",
    "    image = image.cuda()\n",
    "\n",
    "start = time.clock()\n",
    "out = model(image)\n",
    "elapsed = (time.clock() - start)\n",
    "print('cost' + str(elapsed) + 's')\n",
    "out_img = ToPILImage()(out[0].data.cpu())\n",
    "out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_' + IMAGE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
